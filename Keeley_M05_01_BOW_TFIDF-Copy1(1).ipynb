{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "This notebook was derived from a copy of the M05_01_BOW_TFIDF.ipynb file provided by Dr. Alvarado as starter code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```\n",
    "Course:   DS 5001 \n",
    "Module:   05 Lab\n",
    "Topic:    BOW, Vector Spaces, and TFIDF\n",
    "Author:   R.C. Alvarado\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook, we explore Luhn's concept of term significance in light of Zipf's Law, TFIDF, and vector space models of text. \n",
    "\n",
    "Recall Luhn's (1958) representation of the problem:\n",
    "\n",
    "<img src=\"./data_in/luhn.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = \"../data\"\n",
    "local_lib = \"../lib\"\n",
    "data_prefix = 'austen-melville'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTS = OHCO[:4]\n",
    "PARAS = OHCO[:3]\n",
    "CHAPS = OHCO[:2]\n",
    "BOOKS = OHCO[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly_express as px\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/nkeeley/ETA/M5',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python38.zip',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python3.8',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/Users/nkeeley/.local/lib/python3.8/site-packages',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python3.8/site-packages',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python3.8/site-packages/aeosa',\n",
       " '/Users/nkeeley/opt/anaconda3/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/Users/nkeeley/.ipython']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Same code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Acquire Data\n",
    "\n",
    "We grab our **analytical edition** of a selection of works from Austen and Melville."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/output/austen-melville-LIB.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2926bacdb43b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_home}/output/{data_prefix}-LIB.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBOOKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCORPUS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_home}/output/{data_prefix}-CORPUS.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOHCO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mVOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_home}/output/{data_prefix}-VOCAB.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'term_str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mVOCAB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat_pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Drop this column for readability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/output/austen-melville-LIB.csv'"
     ]
    }
   ],
   "source": [
    "LIB = pd.read_csv(f\"{data_home}/output/{data_prefix}-LIB.csv\").set_index(BOOKS)\n",
    "CORPUS = pd.read_csv(f\"{data_home}/output/{data_prefix}-CORPUS.csv\").set_index(OHCO)\n",
    "VOCAB = pd.read_csv(f\"{data_home}/output/{data_prefix}-VOCAB.csv\").set_index('term_str')\n",
    "VOCAB = VOCAB.drop('cat_pos', 1) # Drop this column for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>../data/gutenberg/austen-melville-set/AUSTEN_J...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>PERSUASION</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "      <td>83624</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>../data/gutenberg/austen-melville-set/AUSTEN_J...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>NORTHANGER ABBEY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "      <td>77601</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>../data/gutenberg/austen-melville-set/AUSTEN_J...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>MANSFIELD PARK</td>\n",
       "      <td>^CHAPTER\\s+[IVXLCM]+$</td>\n",
       "      <td>160378</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>../data/gutenberg/austen-melville-set/AUSTEN_J...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>EMMA</td>\n",
       "      <td>^\\s*CHAPTER\\s+[IVXLCM]+\\s*$</td>\n",
       "      <td>160926</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>../data/gutenberg/austen-melville-set/AUSTEN_J...</td>\n",
       "      <td>AUSTEN, JANE</td>\n",
       "      <td>SENSE AND SENSIBILITY</td>\n",
       "      <td>^CHAPTER\\s+\\d+$</td>\n",
       "      <td>119873</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path        author  \\\n",
       "book_id                                                                    \n",
       "105      ../data/gutenberg/austen-melville-set/AUSTEN_J...  AUSTEN, JANE   \n",
       "121      ../data/gutenberg/austen-melville-set/AUSTEN_J...  AUSTEN, JANE   \n",
       "141      ../data/gutenberg/austen-melville-set/AUSTEN_J...  AUSTEN, JANE   \n",
       "158      ../data/gutenberg/austen-melville-set/AUSTEN_J...  AUSTEN, JANE   \n",
       "161      ../data/gutenberg/austen-melville-set/AUSTEN_J...  AUSTEN, JANE   \n",
       "\n",
       "                         title                   chap_regex  book_len  n_chaps  \n",
       "book_id                                                                         \n",
       "105                 PERSUASION              ^Chapter\\s+\\d+$     83624       24  \n",
       "121           NORTHANGER ABBEY              ^CHAPTER\\s+\\d+$     77601       31  \n",
       "141             MANSFIELD PARK        ^CHAPTER\\s+[IVXLCM]+$    160378       48  \n",
       "158                       EMMA  ^\\s*CHAPTER\\s+[IVXLCM]+\\s*$    160926       55  \n",
       "161      SENSE AND SENSIBILITY              ^CHAPTER\\s+\\d+$    119873       50  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>n_pos</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.919781</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>16.527464</td>\n",
       "      <td>CD</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>18.334819</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.919781</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>19.919781</td>\n",
       "      <td>CD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n  n_chars         p          i max_pos  n_pos  stop stem_porter  \\\n",
       "term_str                                                                      \n",
       "0          2        1  0.000001  19.919781      CD      1     0           0   \n",
       "1         21        1  0.000011  16.527464      CD      3     0           1   \n",
       "10         6        2  0.000003  18.334819      CD      1     0          10   \n",
       "100        2        3  0.000001  19.919781      CD      1     0         100   \n",
       "1000       2        4  0.000001  19.919781      CD      1     0        1000   \n",
       "\n",
       "         stem_snowball stem_lancaster  \n",
       "term_str                               \n",
       "0                    0              0  \n",
       "1                    1              1  \n",
       "10                  10             10  \n",
       "100                100            100  \n",
       "1000              1000           1000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenList(['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS.iloc[100000:1000001]\n",
    "CORPUS.index.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Generate BOW Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs: TOKENS (CORPUS) dataframe; a choice of bag (OHCO) level\n",
    "\n",
    "def create_BOW(tokens, level):\n",
    "    \n",
    "    ## Inputs\n",
    "    \n",
    "    bag = level\n",
    "    \n",
    "    ## Create BOW table from tokens table\n",
    "    \n",
    "    bow = tokens.groupby(bag+['term_str']).term_str.count().to_frame('n') \n",
    "    \n",
    "    ## Return values\n",
    "    \n",
    "    return pd.DataFrame(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.39 s, sys: 9.33 s, total: 17.7 s\n",
      "Wall time: 21.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90361"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test out the BOW function\n",
    "\n",
    "%%time\n",
    "a=create_BOW(CORPUS, SENTS)\n",
    "#a.query(\"chap_id==3 & sent_num == 2\")\n",
    "#a.n.unstack()\n",
    "temp=a.reset_index()\n",
    "len(temp.book_id.unique())\n",
    "a.shape\n",
    "a.head(50)\n",
    "#temp.sort_values(by=[\"book_id\",\"chap_id\",\"para_num\", \"sent_num\"]).head(30)\n",
    "a.n.unstack().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    1710128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a.loc[(105,1,2,0)].head()\n",
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs: BOW table, measure\n",
    "\n",
    "def create_TFIDF(bow, tf_method):\n",
    "    \n",
    "    ## Generate DTCM\n",
    "    \n",
    "    DTCM = bow.n.unstack()\n",
    "    \n",
    "    ## Generate TF\n",
    "    \n",
    "    if tf_method == 'sum':\n",
    "        TF = DTCM.T / DTCM.T.sum()\n",
    "    elif tf_method == 'max':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "    elif tf_method == 'log':\n",
    "        TF = np.log10(DTCM.T + 1)\n",
    "    elif tf_method == 'raw':\n",
    "        TF = DTCM.T\n",
    "    elif tf_method == 'bool':\n",
    "        TF = DTCM.T.astype('bool') #.astype('int')\n",
    "    TF = TF.T\n",
    "    \n",
    "    ## Generate IDF\n",
    "    \n",
    "    N=DTCM.shape[0] # The number of chosen bags\n",
    "    DF=DTCM.count() # Vector containing the number of bags containing any term in vocabulary\n",
    "    IDF = np.log10(N / DF)\n",
    "    \n",
    "    ## Compute TFIDF\n",
    "    \n",
    "    TFIDF=TF*IDF\n",
    "    \n",
    "    return TFIDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 =create_TFIDF(a, tf_method=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>10440</th>\n",
       "      <th>10800</th>\n",
       "      <th>10th</th>\n",
       "      <th>118952</th>\n",
       "      <th>...</th>\n",
       "      <th>zoroaster</th>\n",
       "      <th>zozo</th>\n",
       "      <th>zuma</th>\n",
       "      <th>zur</th>\n",
       "      <th>à</th>\n",
       "      <th>æneas</th>\n",
       "      <th>æniad</th>\n",
       "      <th>æson</th>\n",
       "      <th>æsops</th>\n",
       "      <th>ł20000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095526</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34970</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">114</th>\n",
       "      <th>19</th>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90361 rows × 39424 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str                            0         1  10  100  1000  10000  10440  \\\n",
       "book_id chap_id para_num sent_num                                              \n",
       "105     1       1        0        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                         1        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                2        0        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                3        0        NaN  0.232846 NaN  NaN   NaN    NaN    NaN   \n",
       "                         1        NaN  0.095526 NaN  NaN   NaN    NaN    NaN   \n",
       "...                                ..       ...  ..  ...   ...    ...    ...   \n",
       "34970   114     19       3        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                20       0        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                         1        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                21       0        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "                24       0        NaN       NaN NaN  NaN   NaN    NaN    NaN   \n",
       "\n",
       "term_str                           10800  10th  118952  ...  zoroaster  zozo  \\\n",
       "book_id chap_id para_num sent_num                       ...                    \n",
       "105     1       1        0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                         1           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                2        0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                3        0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                         1           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "...                                  ...   ...     ...  ...        ...   ...   \n",
       "34970   114     19       3           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                20       0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                         1           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                21       0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "                24       0           NaN   NaN     NaN  ...        NaN   NaN   \n",
       "\n",
       "term_str                           zuma  zur   à  æneas  æniad  æson  æsops  \\\n",
       "book_id chap_id para_num sent_num                                             \n",
       "105     1       1        0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                         1          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                2        0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                3        0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                         1          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "...                                 ...  ...  ..    ...    ...   ...    ...   \n",
       "34970   114     19       3          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                20       0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                         1          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                21       0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "                24       0          NaN  NaN NaN    NaN    NaN   NaN    NaN   \n",
       "\n",
       "term_str                           ł20000  \n",
       "book_id chap_id para_num sent_num          \n",
       "105     1       1        0            NaN  \n",
       "                         1            NaN  \n",
       "                2        0            NaN  \n",
       "                3        0            NaN  \n",
       "                         1            NaN  \n",
       "...                                   ...  \n",
       "34970   114     19       3            NaN  \n",
       "                20       0            NaN  \n",
       "                         1            NaN  \n",
       "                21       0            NaN  \n",
       "                24       0            NaN  \n",
       "\n",
       "[90361 rows x 39424 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF mean top 20 in corpus using bag: book, max method\n",
    "\n",
    "bow1=create_BOW(CORPUS, BOOKS)\n",
    "bow1.head(30)\n",
    "tfidf1=create_TFIDF(bow1, \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['elinor', 'vernon', 'darcy', 'reginald', 'frederica', 'crawford',\n",
       "       'elliot', 'weston', 'pierre', 'knightley', 'tilney', 'elton', 'bingley',\n",
       "       'wentworth', 'courcy', 'woodhouse', 'churchhill', 'marianne',\n",
       "       'babbalanja', 'mainwaring'],\n",
       "      dtype='object', name='term_str')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Explore\n",
    "\n",
    "result1=tfidf1.apply(np.mean, axis=0)\n",
    "result1.sort_values(ascending=False).head(20).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-811616aa8b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF mean top 20 in corpus using bag: paragraph, max method\n",
    "\n",
    "bow2=create_BOW(CORPUS, PARAS)\n",
    "bow2.head(30)\n",
    "tfidf2=create_TFIDF(bow2, \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term_str\n",
       "0         4.467786\n",
       "1         1.107899\n",
       "10        1.208855\n",
       "100       0.520844\n",
       "1000      0.992085\n",
       "10000     0.624271\n",
       "10440     1.489262\n",
       "10800     0.487023\n",
       "10th      4.166756\n",
       "118952    0.203081\n",
       "11th      4.166756\n",
       "12        2.692202\n",
       "125000    0.893557\n",
       "12th      4.467786\n",
       "13        0.744631\n",
       "13000     1.116946\n",
       "139       0.636588\n",
       "1399      0.372315\n",
       "13th      3.990664\n",
       "140       0.248210\n",
       "dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Explore\n",
    "\n",
    "result2=tfidf2.apply(np.mean, axis=0)\n",
    "result2.sort_values(ascending=False).head(20).index\n",
    "result2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105, 121, 141, 158, 161, 946, 1212, 1342]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Filter IDs\n",
    "\n",
    "LIB.shape # 18 books\n",
    "Austen_ID=list(LIB[LIB.author==\"AUSTEN, JANE\"].index)\n",
    "Austen_ID\n",
    "Melville_ID=list(LIB[LIB.author==\"MELVILLE, HERMAN\"].index)\n",
    "Austen_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flatten CORPUS\n",
    "\n",
    "CORPUS=CORPUS.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>780873</th>\n",
       "      <td>780873</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('THE', 'DT')</td>\n",
       "      <td>DT</td>\n",
       "      <td>THE</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780874</th>\n",
       "      <td>780874</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>('SEA', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>SEA</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780875</th>\n",
       "      <td>780875</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>('LONGINGS', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>LONGINGS</td>\n",
       "      <td>longings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780876</th>\n",
       "      <td>780876</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>('FOR', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>FOR</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780877</th>\n",
       "      <td>780877</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>('SHORE', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>SHORE</td>\n",
       "      <td>shore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984031</th>\n",
       "      <td>1984031</td>\n",
       "      <td>34970</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>('The', 'DT')</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984032</th>\n",
       "      <td>1984032</td>\n",
       "      <td>34970</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>('Ambiguities,', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Ambiguities,</td>\n",
       "      <td>ambiguities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984033</th>\n",
       "      <td>1984033</td>\n",
       "      <td>34970</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>('by', 'IN')</td>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984034</th>\n",
       "      <td>1984034</td>\n",
       "      <td>34970</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>('Herman', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Herman</td>\n",
       "      <td>herman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984035</th>\n",
       "      <td>1984035</td>\n",
       "      <td>34970</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>('Melville', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Melville</td>\n",
       "      <td>melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203163 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  book_id  chap_id  para_num  sent_num  token_num  \\\n",
       "780873    780873     1900        1         0         0          0   \n",
       "780874    780874     1900        1         0         0          1   \n",
       "780875    780875     1900        1         0         0          2   \n",
       "780876    780876     1900        1         0         0          3   \n",
       "780877    780877     1900        1         0         0          4   \n",
       "...          ...      ...      ...       ...       ...        ...   \n",
       "1984031  1984031    34970      114        24         0          6   \n",
       "1984032  1984032    34970      114        24         0          7   \n",
       "1984033  1984033    34970      114        24         0          8   \n",
       "1984034  1984034    34970      114        24         0          9   \n",
       "1984035  1984035    34970      114        24         0         10   \n",
       "\n",
       "                       pos_tuple  pos     token_str     term_str  \n",
       "780873             ('THE', 'DT')   DT           THE          the  \n",
       "780874            ('SEA', 'NNP')  NNP           SEA          sea  \n",
       "780875       ('LONGINGS', 'NNP')  NNP      LONGINGS     longings  \n",
       "780876            ('FOR', 'NNP')  NNP           FOR          for  \n",
       "780877          ('SHORE', 'NNP')  NNP         SHORE        shore  \n",
       "...                          ...  ...           ...          ...  \n",
       "1984031            ('The', 'DT')   DT           The          the  \n",
       "1984032  ('Ambiguities,', 'NNP')  NNP  Ambiguities,  ambiguities  \n",
       "1984033             ('by', 'IN')   IN            by           by  \n",
       "1984034        ('Herman', 'NNP')  NNP        Herman       herman  \n",
       "1984035      ('Melville', 'NNP')  NNP      Melville     melville  \n",
       "\n",
       "[1203163 rows x 10 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make new corpuses\n",
    "\n",
    "Corpus_A=CORPUS[CORPUS.book_id.isin(Austen_ID)]\n",
    "Corpus_A\n",
    "Corpus_B=CORPUS[CORPUS.book_id.isin(Melville_ID)]\n",
    "Corpus_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-339d4a91721c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'book_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chap_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'para_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sent_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'token_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mCorpus_A\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCorpus_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4161\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4162\u001b[0m         \"\"\"\n\u001b[0;32m-> 4163\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4164\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4165\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3885\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3887\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3920\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3921\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5282\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5283\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not found in axis\""
     ]
    }
   ],
   "source": [
    "## Make corpuses narrow again\n",
    "\n",
    "names=['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']\n",
    "Corpus_A=Corpus_A.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus_A=Corpus_A.set_index(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['book_id', 'chap_id', 'para_num', 'sent_num', 'token_num']\n",
    "Corpus_B=Corpus_B.drop(\"index\", axis=1)\n",
    "Corpus_B=Corpus_B.set_index(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1900</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>('THE', 'DT')</td>\n",
       "      <td>DT</td>\n",
       "      <td>THE</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('SEA', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>SEA</td>\n",
       "      <td>sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('LONGINGS', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>LONGINGS</td>\n",
       "      <td>longings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('FOR', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>FOR</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('SHORE', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>SHORE</td>\n",
       "      <td>shore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">34970</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">114</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">24</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>6</th>\n",
       "      <td>('The', 'DT')</td>\n",
       "      <td>DT</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('Ambiguities,', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Ambiguities,</td>\n",
       "      <td>ambiguities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('by', 'IN')</td>\n",
       "      <td>IN</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('Herman', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Herman</td>\n",
       "      <td>herman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('Melville', 'NNP')</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Melville</td>\n",
       "      <td>melville</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1203163 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           pos_tuple  pos  \\\n",
       "book_id chap_id para_num sent_num token_num                                 \n",
       "1900    1       0        0        0                    ('THE', 'DT')   DT   \n",
       "                                  1                   ('SEA', 'NNP')  NNP   \n",
       "                                  2              ('LONGINGS', 'NNP')  NNP   \n",
       "                                  3                   ('FOR', 'NNP')  NNP   \n",
       "                                  4                 ('SHORE', 'NNP')  NNP   \n",
       "...                                                              ...  ...   \n",
       "34970   114     24       0        6                    ('The', 'DT')   DT   \n",
       "                                  7          ('Ambiguities,', 'NNP')  NNP   \n",
       "                                  8                     ('by', 'IN')   IN   \n",
       "                                  9                ('Herman', 'NNP')  NNP   \n",
       "                                  10             ('Melville', 'NNP')  NNP   \n",
       "\n",
       "                                                token_str     term_str  \n",
       "book_id chap_id para_num sent_num token_num                             \n",
       "1900    1       0        0        0                   THE          the  \n",
       "                                  1                   SEA          sea  \n",
       "                                  2              LONGINGS     longings  \n",
       "                                  3                   FOR          for  \n",
       "                                  4                 SHORE        shore  \n",
       "...                                                   ...          ...  \n",
       "34970   114     24       0        6                   The          the  \n",
       "                                  7          Ambiguities,  ambiguities  \n",
       "                                  8                    by           by  \n",
       "                                  9                Herman       herman  \n",
       "                                  10             Melville     melville  \n",
       "\n",
       "[1203163 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>max_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13659</th>\n",
       "      <td>undismayed</td>\n",
       "      <td>0.630937</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9876</th>\n",
       "      <td>precarious</td>\n",
       "      <td>0.229431</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4139</th>\n",
       "      <td>dreary</td>\n",
       "      <td>0.210312</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9530</th>\n",
       "      <td>perverted</td>\n",
       "      <td>0.180268</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>eoconomical</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9443</th>\n",
       "      <td>perfidious</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13849</th>\n",
       "      <td>unpolluted</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9468</th>\n",
       "      <td>pernicious</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13908</th>\n",
       "      <td>unsimpathetic</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9029</th>\n",
       "      <td>opprobious</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            term_str     tfidf max_pos\n",
       "13659     undismayed  0.630937      JJ\n",
       "9876      precarious  0.229431      JJ\n",
       "4139          dreary  0.210312      JJ\n",
       "9530       perverted  0.180268      JJ\n",
       "4631     eoconomical  0.148456      JJ\n",
       "...              ...       ...     ...\n",
       "9443      perfidious  0.007109      JJ\n",
       "13849     unpolluted  0.007109      JJ\n",
       "9468      pernicious  0.007109      JJ\n",
       "13908  unsimpathetic  0.007109      JJ\n",
       "9029      opprobious  0.007109      JJ\n",
       "\n",
       "[992 rows x 3 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate by author TFIDF\n",
    "\n",
    "bow_A=create_BOW(Corpus_A, CHAPS)\n",
    "bow_A.head(30)\n",
    "tfidf_A=create_TFIDF(bow_A, \"max\")\n",
    "\n",
    "## Explore\n",
    "\n",
    "result_A=tfidf_A.apply(np.mean, axis=0)\n",
    "result_A.sort_values(ascending=False).head(20).index\n",
    "result_A=pd.DataFrame(result_A)\n",
    "result_A=result_A.rename(columns={0:\"tfidf\"})\n",
    "result_A\n",
    "result_A=result_A.reset_index()\n",
    "result_A=result_A.sort_values(by=\"term_str\")\n",
    "result_A[\"max_pos\"]=max_pos_A.max_pos\n",
    "result_A=result_A.sort_values([\"tfidf\"],ascending=False)\n",
    "result_A[result_A.max_pos==\"JJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>max_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19638</th>\n",
       "      <td>manchineels</td>\n",
       "      <td>0.450680</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12861</th>\n",
       "      <td>forereaching</td>\n",
       "      <td>0.225340</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25777</th>\n",
       "      <td>quoggy</td>\n",
       "      <td>0.225340</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34437</th>\n",
       "      <td>unpolluted</td>\n",
       "      <td>0.225340</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16337</th>\n",
       "      <td>incestuous</td>\n",
       "      <td>0.220186</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34038</th>\n",
       "      <td>unentered</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>austere</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28616</th>\n",
       "      <td>serried</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33898</th>\n",
       "      <td>underbush</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22725</th>\n",
       "      <td>owlee</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2283 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           term_str     tfidf max_pos\n",
       "19638   manchineels  0.450680      JJ\n",
       "12861  forereaching  0.225340      JJ\n",
       "25777        quoggy  0.225340      JJ\n",
       "34437    unpolluted  0.225340      JJ\n",
       "16337    incestuous  0.220186      JJ\n",
       "...             ...       ...     ...\n",
       "34038     unentered  0.005051      JJ\n",
       "2237        austere  0.005051      JJ\n",
       "28616       serried  0.005051      JJ\n",
       "33898     underbush  0.004599      JJ\n",
       "22725         owlee  0.004599      JJ\n",
       "\n",
       "[2283 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate by author TFIDF\n",
    "\n",
    "bow_B=create_BOW(Corpus_B, CHAPS)\n",
    "bow_B.head(30)\n",
    "tfidf_B=create_TFIDF(bow_B, \"max\")\n",
    "\n",
    "## Explore\n",
    "\n",
    "result_B=tfidf_B.apply(np.mean, axis=0)\n",
    "result_B.sort_values(ascending=False).head(20).index\n",
    "result_B=pd.DataFrame(result_B)\n",
    "result_B=result_B.rename(columns={0:\"tfidf\"})\n",
    "result_B\n",
    "result_B=result_B.reset_index()\n",
    "result_B=result_B.sort_values(by=\"term_str\")\n",
    "result_B[\"max_pos\"]=max_pos_B.max_pos\n",
    "result_B=result_B.sort_values([\"tfidf\"],ascending=False)\n",
    "result_B[result_B.max_pos==\"JJ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>10000</th>\n",
       "      <th>10th</th>\n",
       "      <th>11th</th>\n",
       "      <th>12</th>\n",
       "      <th>12th</th>\n",
       "      <th>1399</th>\n",
       "      <th>13th</th>\n",
       "      <th>...</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youths</th>\n",
       "      <th>yrs</th>\n",
       "      <th>z</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zigzags</th>\n",
       "      <th>ł20000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">105</th>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1342</th>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows × 14745 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term_str          0        1  10  10000  10th  11th  12  12th  1399  13th  \\\n",
       "book_id chap_id                                                             \n",
       "105     1       NaN  0.03585 NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        2       NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        3       NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        4       NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        5       NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "...              ..      ...  ..    ...   ...   ...  ..   ...   ...   ...   \n",
       "1342    57      NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        58      NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        59      NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        60      NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "        61      NaN      NaN NaN    NaN   NaN   NaN NaN   NaN   NaN   NaN   \n",
       "\n",
       "term_str         ...  youthful  youths  yrs         z      zeal  zealous  \\\n",
       "book_id chap_id  ...                                                       \n",
       "105     1        ...   0.01307     NaN  NaN  0.020353       NaN      NaN   \n",
       "        2        ...       NaN     NaN  NaN       NaN       NaN  0.01857   \n",
       "        3        ...       NaN     NaN  NaN       NaN  0.011138      NaN   \n",
       "        4        ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "        5        ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "...              ...       ...     ...  ...       ...       ...      ...   \n",
       "1342    57       ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "        58       ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "        59       ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "        60       ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "        61       ...       NaN     NaN  NaN       NaN       NaN      NaN   \n",
       "\n",
       "term_str         zealously  zephyr  zigzags  ł20000  \n",
       "book_id chap_id                                      \n",
       "105     1              NaN     NaN      NaN     NaN  \n",
       "        2              NaN     NaN      NaN     NaN  \n",
       "        3              NaN     NaN      NaN     NaN  \n",
       "        4              NaN     NaN      NaN     NaN  \n",
       "        5              NaN     NaN      NaN     NaN  \n",
       "...                    ...     ...      ...     ...  \n",
       "1342    57             NaN     NaN      NaN     NaN  \n",
       "        58             NaN     NaN      NaN     NaN  \n",
       "        59             NaN     NaN      NaN     NaN  \n",
       "        60             NaN     NaN      NaN     NaN  \n",
       "        61             NaN     NaN      NaN     NaN  \n",
       "\n",
       "[334 rows x 14745 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>max_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36831</th>\n",
       "      <td>à</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36832</th>\n",
       "      <td>æneas</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36833</th>\n",
       "      <td>æniad</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36834</th>\n",
       "      <td>æson</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36835</th>\n",
       "      <td>æsops</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36836 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      term_str max_pos\n",
       "0            1     NNP\n",
       "1           10      CD\n",
       "2          100      CD\n",
       "3         1000      CD\n",
       "4        10000      CD\n",
       "...        ...     ...\n",
       "36831        à     NNP\n",
       "36832    æneas      NN\n",
       "36833    æniad      NN\n",
       "36834     æson      NN\n",
       "36835    æsops     NNS\n",
       "\n",
       "[36836 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate max pos\n",
    "\n",
    "max_pos_A=Corpus_A.groupby(\"term_str\").agg({\"pos\":\"max\"})\n",
    "max_pos_A.rename(columns={\"pos\":\"max_pos\"}, inplace=True)\n",
    "max_pos_A=max_pos_A.reset_index()\n",
    "max_pos_A=max_pos_A.sort_values(by=\"term_str\")\n",
    "max_pos_A\n",
    "\n",
    "max_pos_B=Corpus_B.groupby(\"term_str\").agg({\"pos\":\"max\"})\n",
    "max_pos_B.rename(columns={\"pos\":\"max_pos\"}, inplace=True)\n",
    "max_pos_B=max_pos_B.reset_index()\n",
    "max_pos_B=max_pos_B.sort_values(by=\"term_str\")\n",
    "\n",
    "max_pos_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>max_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5675</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23386</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24024</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32142</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14101</th>\n",
       "      <td>à</td>\n",
       "      <td>5</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27767</th>\n",
       "      <td>æneas</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30059</th>\n",
       "      <td>æniad</td>\n",
       "      <td>1</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>æson</td>\n",
       "      <td>2</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29248</th>\n",
       "      <td>æsops</td>\n",
       "      <td>1</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        term_str   n max_pos\n",
       "term_id                     \n",
       "5675           1  18     VBN\n",
       "23386         10   2     NNP\n",
       "24024        100   2     NNP\n",
       "24473       1000   2      VB\n",
       "32142      10000   1     NNS\n",
       "...          ...  ..     ...\n",
       "14101          à   5      RB\n",
       "27767      æneas   1      NN\n",
       "30059      æniad   1     NNP\n",
       "23217       æson   2      NN\n",
       "29248      æsops   1      NN\n",
       "\n",
       "[36836 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create vocabs and merge with max_pos\n",
    "\n",
    "VOCAB_A = Corpus_A.term_str.value_counts().to_frame('n').reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB_A.index.name = 'term_id'\n",
    "VOCAB_A=VOCAB_A.sort_values(by=\"term_str\")\n",
    "VOCAB_A[\"max_pos\"]=max_pos_A.max_pos\n",
    "VOCAB_A\n",
    "\n",
    "VOCAB_B = Corpus_B.term_str.value_counts().to_frame('n').reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB_B.index.name = 'term_id'\n",
    "VOCAB_B=VOCAB_B.sort_values(by=\"term_str\")\n",
    "VOCAB_B[\"max_pos\"]=max_pos_B.max_pos\n",
    "VOCAB_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the vocabs to see most common POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather POS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_home' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-769cb62b77fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{data_home}/misc/upenn_tagset.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m POS = pd.DataFrame([(line.split()[0], ' '.join(line.split()[1:])) \n\u001b[1;32m      3\u001b[0m                     for line in open(pos_info, 'r').readlines()])\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# POS.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_home' is not defined"
     ]
    }
   ],
   "source": [
    "pos_info = f'{data_home}/misc/upenn_tagset.txt'\n",
    "POS = pd.DataFrame([(line.split()[0], ' '.join(line.split()[1:])) \n",
    "                    for line in open(pos_info, 'r').readlines()])\n",
    "# POS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'POS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9a3d840c1a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'pos_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos_def'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'POS' is not defined"
     ]
    }
   ],
   "source": [
    "POS.columns = ['pos_id', 'pos_def']\n",
    "POS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'POS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6420b5b0215c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pos_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mPOS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'POS' is not defined"
     ]
    }
   ],
   "source": [
    "POS = POS.set_index('pos_id')\n",
    "POS['pos_group'] = POS.apply(lambda x: x.name[:2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'POS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b89ce9a32e3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPOS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'POS' is not defined"
     ]
    }
   ],
   "source": [
    "POS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VOCAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5935b36011f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_pos_group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCORPUS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos_group'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCORPUS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VOCAB' is not defined"
     ]
    }
   ],
   "source": [
    "VOCAB['max_pos_group'] =  VOCAB.max_pos.apply(lambda x: x[:2])\n",
    "CORPUS['pos_group'] = CORPUS.pos.apply(lambda x: x[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipf's Law\n",
    "\n",
    "First, we explore Zipf's Law, which may be expressed by $f \\propto \\frac{1}{r}$ and the constant $k =  fr$.\n",
    "\n",
    "Essentially, it says the frequency of tokens in a language is logarithmic. It is a property of all known human languages. \n",
    "\n",
    "Specifically, it says the tokens can be ranked $r = 1,2,3,4, \\dots ,N$ where (1) the rank is inversely proportional to the frequency, i.e. the lower the rank number, the higher the frequency, and (2) the frequency of a rank $r$ word is $1/r$ times that the most frequent word $r = 1$. So, the rank 2 word occurs half as often as the rank 1 word, the rank 3 word one-third as often, the rank 4 word one-fourth as often, and so forth. The law breaks down at around $r = 1000$.\n",
    "\n",
    "The law turns out to need some tweaking. \n",
    "\n",
    "Here we try to reproduce it with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VOCAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-30bc010a2023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'VOCAB' is not defined"
     ]
    }
   ],
   "source": [
    "VOCAB.n.sort_values().plot(logy=True, style='.', rot=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Term Rank $r$ to `VOCAB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'term_rank' not in VOCAB.columns:\n",
    "    VOCAB = VOCAB.sort_values('n', ascending=False).reset_index()\n",
    "    VOCAB.index.name = 'term_rank'\n",
    "    VOCAB = VOCAB.reset_index()\n",
    "    VOCAB['term_rank'] = VOCAB['term_rank'] + 1\n",
    "    VOCAB = VOCAB.set_index('term_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.term_rank.plot(logx=False, rot=45, title=\"Y = Rank\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Rank\n",
    "\n",
    "Note this the above method does not group words with the same frequency, and thus arbitrarily assigns ranks for words with the same frequency. So we try coming up with rank as a grouping feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rank = VOCAB.n.value_counts()\\\n",
    "    .sort_index(ascending=False).reset_index().reset_index()\\\n",
    "    .rename(columns={'level_0':'term_rank2', 'index':'n', 'n':'nn'})\\\n",
    "    .set_index('n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rank\n",
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['term_rank2'] = VOCAB.n.map(new_rank.term_rank2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.term_rank2.plot(logx=False, rot=45, title=\"Y = Rank\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Zipf's $k$\n",
    "\n",
    "We compute $k$ using both types of rank. Note that this *should* be a constant, but it is not. This is a function of the data size (support) and the fact that Zipf's law is not perfect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['zipf_k'] = VOCAB.n * VOCAB.term_rank\n",
    "VOCAB['zipf_k2'] = VOCAB.n * VOCAB.term_rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.zipf_k.plot(style=',', rot=45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.zipf_k2.plot(style=',', rot=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Rank and N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(VOCAB.reset_index(), \n",
    "           x='term_rank2', y='n', \n",
    "           log_y=False, log_x=False,\n",
    "           hover_name='term_str',\n",
    "           color='max_pos_group',\n",
    "           height=500, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Demo Rank Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_index = [1, 2, 3, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 450, 500, 550, 600, 700, 800]\n",
    "demo = VOCAB.loc[VOCAB.term_rank2.isin(rank_index), \n",
    "                 ['term_rank2', 'n', 'zipf_k2', 'max_pos']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.style.background_gradient(cmap='YlGnBu', high=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = CHAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_method = 'n'      # 'c' or 'n' # n = n tokens, c = distinct token (term) count\n",
    "# tf_method = 'sum'       # sum, max, log, double_norm, raw, binary\n",
    "# tf_norm_k = .5          # only used for double_norm\n",
    "# idf_method = 'standard' # standard, max, smooth\n",
    "gradient_cmap = 'GnBu'  # YlGn, GnBu, YlGnBu; For tables; see https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW = CORPUS.groupby(bag+['term_str']).term_str.count().to_frame('n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW['c'] = BOW.n.astype('bool').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW.loc[(105,2)].sort_values('n', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Document-Term Matrix\n",
    "\n",
    "We create a document-term count matrix. Note that we can create a matrix for any of the features in BOW. Also, see how the OHCO helps us distinguish between features and observation identity.\n",
    "\n",
    "Note, these operations are slower than using `groupby()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Count Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTCM = BOW[count_method].unstack() #.fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCM = BOW.n.unstack() #.fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCM.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_method = 'sum' # sum, max, log, double_norm, raw, binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TF method:', tf_method)\n",
    "if tf_method == 'sum':\n",
    "    TF = DTCM.T / DTCM.T.sum()\n",
    "elif tf_method == 'max':\n",
    "    TF = DTCM.T / DTCM.T.max()\n",
    "elif tf_method == 'log':\n",
    "    TF = np.log10(DTCM.T + 1)\n",
    "elif tf_method == 'raw':\n",
    "    TF = DTCM.T\n",
    "elif tf_method == 'bool':\n",
    "    TF = DTCM.T.astype('bool') #.astype('int')\n",
    "TF = TF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF = DTCM[DTCM > 0].count()\n",
    "DF = DTCM.count() # THIS WORKS IF WE KEPT NULLS IN DTCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_method = 'standard' # standard, max, smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = DTCM.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('IDF method:', idf_method)\n",
    "if idf_method == 'standard':\n",
    "    IDF = np.log10(N / DF)\n",
    "elif idf_method == 'max':\n",
    "    IDF = np.log10(DF.max() / DF) \n",
    "elif idf_method == 'smooth':\n",
    "    IDF = np.log10((1 + N) / (1 + DF)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TF * IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move things to their places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['df'] = DF\n",
    "VOCAB['idf'] = IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW['tf'] = TF.stack()\n",
    "BOW['tfidf'] = TFIDF.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add aggregates to VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['tfidf_mean'] = TFIDF[TFIDF > 0].mean().fillna(0) # EXPLAIN\n",
    "VOCAB['tfidf_max'] = TFIDF.max()\n",
    "VOCAB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VOCAB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-51e8cd1e8a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVOCAB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dfidf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVOCAB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'VOCAB' is not defined"
     ]
    }
   ],
   "source": [
    "VOCAB['dfidf'] = VOCAB.df * VOCAB.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(VOCAB.reset_index(), x='term_rank2', y='dfidf', color='max_pos', hover_name='term_str', height=500, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `DFIDF` look like?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observe results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = \"n term_rank2 zipf_k2 max_pos tfidf_mean tfidf_max dfidf\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB[my_cols].sort_values('term_rank2', ascending=True).head(100).style.background_gradient(cmap=gradient_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB[my_cols].sort_values('tfidf_mean', ascending=False).head(50)\\\n",
    "    .style.background_gradient(cmap=gradient_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB[my_cols].sort_values('dfidf', ascending=False).head(50)\\\n",
    "    .style.background_gradient(cmap=gradient_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW.sort_values('tfidf', ascending=False).head(20).style.background_gradient(cmap=gradient_cmap, high=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## More Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank and TFIDF Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(VOCAB.reset_index(), \n",
    "           x='term_rank2', y='tfidf_mean', \n",
    "           color='max_pos', size='n_pos',\n",
    "           hover_name='term_str', hover_data=['n','i'],\n",
    "           log_y=True, log_x=False,\n",
    "#            height=500, width=800\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(VOCAB.reset_index(), \n",
    "           x='term_rank2', y='dfidf', \n",
    "           color='max_pos', size='n_pos',\n",
    "           hover_name='term_str', hover_data=['n','i'],\n",
    "#            height=500, width=800\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Demo Table with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo2 = VOCAB.loc[VOCAB.term_rank2.isin(rank_index), my_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo2.style.background_gradient(cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Reduce VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_col = 'dfidf'\n",
    "key_quantile = .9\n",
    "key_min = VOCAB[key_col].quantile(key_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGS = VOCAB.loc[VOCAB[key_col] >= key_min].sort_values(key_col, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGS.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGS[my_cols].sample(100).style.background_gradient(cmap=gradient_cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv(f'{data_home}/output/{data_prefix}-VOCAB2.csv') # USED IN HW\n",
    "CORPUS.to_csv(f'{data_home}/output/{data_prefix}-CORPUS2.csv')\n",
    "BOW.to_csv(f'{data_home}/output/{data_prefix}-BOW.csv')\n",
    "DTCM.to_csv(f'{data_home}/output/{data_prefix}-DTCM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF.to_csv(f'{data_home}/output/{data_prefix}-TFIDF.csv')\n",
    "SIGS.to_csv(f'{data_home}/output/{data_prefix}-SIGS.csv')\n",
    "WCM.to_csv(f'{data_home}/output/{data_prefix}-WCM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF[SIGS.index].to_csv('{}/{}-TFIDF_REDUCED.csv'.format(data_out, data_prefix))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "235.517px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
